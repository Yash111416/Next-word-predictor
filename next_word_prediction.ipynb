{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Text Generation - Next Word Prediction"
      ],
      "metadata": {
        "id": "DWyTxKbqVfLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Functions for Processing Text\n",
        "\n",
        "### a. Reading in files as a string text"
      ],
      "metadata": {
        "id": "6FnWWxBXVfLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filepath):\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "\n",
        "    return str_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:41:39.386375Z",
          "iopub.execute_input": "2021-11-20T16:41:39.386635Z",
          "iopub.status.idle": "2021-11-20T16:41:39.390698Z",
          "shell.execute_reply.started": "2021-11-20T16:41:39.386605Z",
          "shell.execute_reply": "2021-11-20T16:41:39.390021Z"
        },
        "trusted": true,
        "id": "rMn8iokLVfLK"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"rahul\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:34.657458Z",
          "iopub.execute_input": "2021-11-20T16:07:34.657778Z",
          "iopub.status.idle": "2021-11-20T16:07:34.669511Z",
          "shell.execute_reply.started": "2021-11-20T16:07:34.657735Z",
          "shell.execute_reply": "2021-11-20T16:07:34.668844Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhXDFjrbVfLL",
        "outputId": "cff3f80a-fdad-4b80-93c9-8ab4b4aa713b"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(read_file('whale2.txt'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:34.671943Z",
          "iopub.execute_input": "2021-11-20T16:07:34.672662Z",
          "iopub.status.idle": "2021-11-20T16:07:34.685321Z",
          "shell.execute_reply.started": "2021-11-20T16:07:34.672624Z",
          "shell.execute_reply": "2021-11-20T16:07:34.684603Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LTOsWhkVfLL",
        "outputId": "b4cbd2c6-9fd5-4d67-df92-809a674e6cee"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1215236"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(read_file('whale2.txt')[:5000])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:34.688291Z",
          "iopub.execute_input": "2021-11-20T16:07:34.688843Z",
          "iopub.status.idle": "2021-11-20T16:07:34.699651Z",
          "shell.execute_reply.started": "2021-11-20T16:07:34.688789Z",
          "shell.execute_reply": "2021-11-20T16:07:34.699007Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXuzq8D7VfLL",
        "outputId": "5b66e2e4-ad7d-4bc2-c62e-66d46d152226"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ETYMOLOGY.\n",
            "\n",
            "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
            "\n",
            "The pale Usher--threadbare in coat, heart, body, and brain; I see him now. He was ever dusting his old lexicons and grammars, with a queer handkerchief, mockingly embellished with all the gay flags of all the known nations of the world. He loved to dust his old grammars; it somehow mildly reminded him of his mortality.\n",
            "\n",
            "\"While you take in hand to school others, and to teach them by what name a whale-fish is to be called in our tongue leaving out, through ignorance, the letter H, which almost alone maketh the signification of the word, you deliver that which is not true.\" --HACKLUYT\n",
            "\n",
            "\"WHALE.... Sw. and Dan. HVAL. This animal is named from roundness or rolling; for in Dan. HVALT is arched or vaulted.\" --WEBSTER'S DICTIONARY\n",
            "\n",
            "\"WHALE.... It is more immediately from the Dut. and Ger. WALLEN; A.S. WALW-IAN, to roll, to wallow.\" --RICHARDSON'S DICTIONARY\n",
            "\n",
            "     KETOS,               GREEK.\n",
            "     CETUS,               LATIN.\n",
            "     WHOEL,               ANGLO-SAXON.\n",
            "     HVALT,               DANISH.\n",
            "     WAL,                 DUTCH.\n",
            "     HWAL,                SWEDISH.\n",
            "     WHALE,               ICELANDIC.\n",
            "     WHALE,               ENGLISH.\n",
            "     BALEINE,             FRENCH.\n",
            "     BALLENA,             SPANISH.\n",
            "     PEKEE-NUEE-NUEE,     FEGEE.\n",
            "     PEHEE-NUEE-NUEE,     ERROMANGOAN.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "EXTRACTS (Supplied by a Sub-Sub-Librarian).\n",
            "\n",
            "It will be seen that this mere painstaking burrower and grub-worm of a poor devil of a Sub-Sub appears to have gone through the long Vaticans and street-stalls of the earth, picking up whatever random allusions to whales he could anyways find in any book whatsoever, sacred or profane. Therefore you must not, in every case at least, take the higgledy-piggledy whale statements, however authentic, in these extracts, for veritable gospel cetology. Far from it. As touching the ancient authors generally, as well as the poets here appearing, these extracts are solely valuable or entertaining, as affording a glancing bird's eye view of what has been promiscuously said, thought, fancied, and sung of Leviathan, by many nations and generations, including our own.\n",
            "\n",
            "So fare thee well, poor devil of a Sub-Sub, whose commentator I am. Thou belongest to that hopeless, sallow tribe which no wine of this world will ever warm; and for whom even Pale Sherry would be too rosy-strong; but with whom one sometimes loves to sit, and feel poor-devilish, too; and grow convivial upon tears; and say to them bluntly, with full eyes and empty glasses, and in not altogether unpleasant sadness--Give it up, Sub-Subs! For by how much the more pains ye take to please the world, by so much the more shall ye for ever go thankless! Would that I could clear out Hampton Court and the Tuileries for ye! But gulp down your tears and hie aloft to the royal-mast with your hearts; for your friends who have gone before are clearing out the seven-storied heavens, and making refugees of long-pampered Gabriel, Michael, and Raphael, against your coming. Here ye strike but splintered hearts together--there, ye shall strike unsplinterable glasses!\n",
            "\n",
            "\n",
            "EXTRACTS.\n",
            "\n",
            "\"And God created great whales.\" --GENESIS.\n",
            "\n",
            "\"Leviathan maketh a path to shine after him; One would think the deep to be hoary.\" --JOB.\n",
            "\n",
            "\"Now the Lord had prepared a great fish to swallow up Jonah.\" --JONAH.\n",
            "\n",
            "\"There go the ships; there is that Leviathan whom thou hast made to play therein.\" --PSALMS.\n",
            "\n",
            "\"In that day, the Lord with his sore, and great, and strong sword, shall punish Leviathan the piercing serpent, even Leviathan that crooked serpent; and he shall slay the dragon that is in the sea.\" --ISAIAH\n",
            "\n",
            "\"And what thing soever besides cometh within the chaos of this monster's mouth, be it beast, boat, or stone, down it goes all incontinently that foul great swallow of his, and perisheth in the bottomless gulf of his paunch.\" --HOLLAND'S PLUTARCH'S MORALS.\n",
            "\n",
            "\"The Indian Sea breedeth the most and the biggest fishes that are: among which the Whales and Whirlpooles called Balaene, take up as much in length as four acres or arpens of land.\" --HOLLAND'S PLINY.\n",
            "\n",
            "\"Scarcely had we proceeded two days on the sea, when about sunrise a great many Whales and other monsters of the sea, appeared. Among the former, one was of a most monstrous size.... This came towards us, open-mouthed, raising the waves on all sides, and beating the sea before him into a foam.\" --TOOKE'S LUCIAN. \"THE TRUE HISTORY.\"\n",
            "\n",
            "\"He visited this country also with a view of catching horse-whales, which had bones of very great value for their teeth, of which he brought some to the king.... The best whales were catched in his own country, of which some were forty-eight, some fifty yards long. He said that he was one of six who had killed sixty in two days.\" --OTHER OR OTHER'S VERBAL NARRATIVE TAKEN DOWN FROM HIS MOUTH BY KING ALFRED, A.D. 890.\n",
            "\n",
            "\"And whereas all the other things, whether beast or vessel, that enter into the dreadful gulf of this monster's (whale's) mouth, are i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b. Tokenize and Clean Text"
      ],
      "metadata": {
        "id": "lpAvyx_IVfLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "nlp.max_length = 1198623"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:34.700879Z",
          "iopub.execute_input": "2021-11-20T16:07:34.701397Z",
          "iopub.status.idle": "2021-11-20T16:07:43.886089Z",
          "shell.execute_reply.started": "2021-11-20T16:07:34.701361Z",
          "shell.execute_reply": "2021-11-20T16:07:43.885292Z"
        },
        "trusted": true,
        "id": "kyB9S3zgVfLM"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(filepath):\n",
        "\n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "\n",
        "    return str_text[:250000]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:43.887563Z",
          "iopub.execute_input": "2021-11-20T16:07:43.887857Z",
          "iopub.status.idle": "2021-11-20T16:07:43.892824Z",
          "shell.execute_reply.started": "2021-11-20T16:07:43.887821Z",
          "shell.execute_reply": "2021-11-20T16:07:43.891830Z"
        },
        "trusted": true,
        "id": "EHiCfc8IVfLM"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:43.894359Z",
          "iopub.execute_input": "2021-11-20T16:07:43.894978Z",
          "iopub.status.idle": "2021-11-20T16:07:43.902918Z",
          "shell.execute_reply.started": "2021-11-20T16:07:43.894866Z",
          "shell.execute_reply": "2021-11-20T16:07:43.902145Z"
        },
        "trusted": true,
        "id": "XwdM8VkKVfLN"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = read_file('whale2.txt')\n",
        "tokens = separate_punc(d)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:07:43.904147Z",
          "iopub.execute_input": "2021-11-20T16:07:43.904605Z",
          "iopub.status.idle": "2021-11-20T16:08:00.763489Z",
          "shell.execute_reply.started": "2021-11-20T16:07:43.904568Z",
          "shell.execute_reply": "2021-11-20T16:08:00.762700Z"
        },
        "trusted": true,
        "id": "X29HI9QdVfLN"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.764991Z",
          "iopub.execute_input": "2021-11-20T16:08:00.765250Z",
          "iopub.status.idle": "2021-11-20T16:08:00.770547Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.765215Z",
          "shell.execute_reply": "2021-11-20T16:08:00.769841Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tckJkET0VfLN",
        "outputId": "3e802651-5704-4ae9-d956-48fb9065615a"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.771908Z",
          "iopub.execute_input": "2021-11-20T16:08:00.772450Z",
          "iopub.status.idle": "2021-11-20T16:08:00.782045Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.772414Z",
          "shell.execute_reply": "2021-11-20T16:08:00.781238Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLCC6IxsVfLN",
        "outputId": "96e0e2a8-33c5-40ac-bf2d-b4da8d3c52a8"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45455"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.783485Z",
          "iopub.execute_input": "2021-11-20T16:08:00.784033Z",
          "iopub.status.idle": "2021-11-20T16:08:00.792918Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.783995Z",
          "shell.execute_reply": "2021-11-20T16:08:00.792125Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_68if_RVfLN",
        "outputId": "d20dfd23-0759-4429-f582-40fea2082162"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['etymology',\n",
              " 'supplied',\n",
              " 'by',\n",
              " 'a',\n",
              " 'late',\n",
              " 'consumptive',\n",
              " 'usher',\n",
              " 'to',\n",
              " 'a',\n",
              " 'grammar']"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c. Create Sequences of Tokens"
      ],
      "metadata": {
        "id": "3XWD8BobVfLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# organize into sequences of tokens\n",
        "train_len = 25+1 # 25 training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "\n",
        "    # Grab train_len# amount of characters\n",
        "    seq = tokens[i-train_len:i]\n",
        "\n",
        "    # Add to list of sequences\n",
        "    text_sequences.append(seq)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.794257Z",
          "iopub.execute_input": "2021-11-20T16:08:00.794515Z",
          "iopub.status.idle": "2021-11-20T16:08:00.836440Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.794481Z",
          "shell.execute_reply": "2021-11-20T16:08:00.835767Z"
        },
        "trusted": true,
        "id": "eMgWa0XiVfLN"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(read_file('whale2.txt')[:1000])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.840070Z",
          "iopub.execute_input": "2021-11-20T16:08:00.840276Z",
          "iopub.status.idle": "2021-11-20T16:08:00.849189Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.840252Z",
          "shell.execute_reply": "2021-11-20T16:08:00.848091Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWI8gfFkVfLN",
        "outputId": "b97719b3-ee39-4c1d-e583-0b6c60766b5e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ETYMOLOGY.\n",
            "\n",
            "(Supplied by a Late Consumptive Usher to a Grammar School)\n",
            "\n",
            "The pale Usher--threadbare in coat, heart, body, and brain; I see him now. He was ever dusting his old lexicons and grammars, with a queer handkerchief, mockingly embellished with all the gay flags of all the known nations of the world. He loved to dust his old grammars; it somehow mildly reminded him of his mortality.\n",
            "\n",
            "\"While you take in hand to school others, and to teach them by what name a whale-fish is to be called in our tongue leaving out, through ignorance, the letter H, which almost alone maketh the signification of the word, you deliver that which is not true.\" --HACKLUYT\n",
            "\n",
            "\"WHALE.... Sw. and Dan. HVAL. This animal is named from roundness or rolling; for in Dan. HVALT is arched or vaulted.\" --WEBSTER'S DICTIONARY\n",
            "\n",
            "\"WHALE.... It is more immediately from the Dut. and Ger. WALLEN; A.S. WALW-IAN, to roll, to wallow.\" --RICHARDSON'S DICTIONARY\n",
            "\n",
            "     KETOS,               GREEK.\n",
            "     CETUS,               LATIN.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.851237Z",
          "iopub.execute_input": "2021-11-20T16:08:00.851932Z",
          "iopub.status.idle": "2021-11-20T16:08:00.857848Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.851893Z",
          "shell.execute_reply": "2021-11-20T16:08:00.857090Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sRzjdBFIVfLN",
        "outputId": "6ced7f12-5569-459b-939f-e9ff7486a412"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'etymology supplied by a late consumptive usher to a grammar school the pale usher threadbare in coat heart body and brain i see him now he'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.859092Z",
          "iopub.execute_input": "2021-11-20T16:08:00.859592Z",
          "iopub.status.idle": "2021-11-20T16:08:00.868691Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.859497Z",
          "shell.execute_reply": "2021-11-20T16:08:00.867974Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wbXHlUSaVfLO",
        "outputId": "f1cc71d9-bd7e-4c71-e053-ffd755dda027"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'supplied by a late consumptive usher to a grammar school the pale usher threadbare in coat heart body and brain i see him now he was'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.870338Z",
          "iopub.execute_input": "2021-11-20T16:08:00.871128Z",
          "iopub.status.idle": "2021-11-20T16:08:00.877273Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.871088Z",
          "shell.execute_reply": "2021-11-20T16:08:00.876372Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8V7zgl4HVfLO",
        "outputId": "b461bcad-3b42-49e4-b38e-ffbabc7477c1"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'by a late consumptive usher to a grammar school the pale usher threadbare in coat heart body and brain i see him now he was ever'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_sequences) #Every sentence is containing 26 words"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.878650Z",
          "iopub.execute_input": "2021-11-20T16:08:00.878969Z",
          "iopub.status.idle": "2021-11-20T16:08:00.887016Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.878935Z",
          "shell.execute_reply": "2021-11-20T16:08:00.886164Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kapYFG9JVfLO",
        "outputId": "1970f87c-7d45-467e-8f8d-a7518b3f89b4"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45429"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens) # These are total number of words in the whole novel"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.888909Z",
          "iopub.execute_input": "2021-11-20T16:08:00.890397Z",
          "iopub.status.idle": "2021-11-20T16:08:00.897160Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.890365Z",
          "shell.execute_reply": "2021-11-20T16:08:00.896355Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgoNRyXHVfLO",
        "outputId": "4eedeaa1-d95c-4af4-b7b1-fdd8cf9a51b9"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45455"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(text_sequences[0]))\n",
        "print(text_sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.898470Z",
          "iopub.execute_input": "2021-11-20T16:08:00.899021Z",
          "iopub.status.idle": "2021-11-20T16:08:00.905690Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.898971Z",
          "shell.execute_reply": "2021-11-20T16:08:00.904966Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLTKSJFvVfLO",
        "outputId": "2e741cb4-8db7-4cde-a3a4-ae977be2d89f"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "['etymology', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', 'the', 'pale', 'usher', 'threadbare', 'in', 'coat', 'heart', 'body', 'and', 'brain', 'i', 'see', 'him', 'now', 'he']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### d. Keras Tokenization"
      ],
      "metadata": {
        "id": "EMhsry3-VfLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:00.906990Z",
          "iopub.execute_input": "2021-11-20T16:08:00.907403Z",
          "iopub.status.idle": "2021-11-20T16:08:01.446849Z",
          "shell.execute_reply.started": "2021-11-20T16:08:00.907367Z",
          "shell.execute_reply": "2021-11-20T16:08:01.446056Z"
        },
        "trusted": true,
        "id": "HNF4SkpcVfLO"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:01.450107Z",
          "iopub.execute_input": "2021-11-20T16:08:01.450330Z",
          "iopub.status.idle": "2021-11-20T16:08:02.940457Z",
          "shell.execute_reply.started": "2021-11-20T16:08:01.450303Z",
          "shell.execute_reply": "2021-11-20T16:08:02.939664Z"
        },
        "trusted": true,
        "id": "5hNrqhynVfLO"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sequences[0]))\n",
        "print(sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.943968Z",
          "iopub.execute_input": "2021-11-20T16:08:02.944178Z",
          "iopub.status.idle": "2021-11-20T16:08:02.952077Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.944151Z",
          "shell.execute_reply": "2021-11-20T16:08:02.950352Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXXWpZLwVfLO",
        "outputId": "6cb40bf9-a72a-48b2-882b-2deb1465a351"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "[7162, 1346, 30, 4, 476, 7161, 7157, 5, 4, 7160, 1893, 1, 1892, 7157, 7158, 6, 475, 276, 513, 2, 1891, 7, 91, 22, 39, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer.index_word)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.953524Z",
          "iopub.execute_input": "2021-11-20T16:08:02.953809Z",
          "iopub.status.idle": "2021-11-20T16:08:02.961145Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.953755Z",
          "shell.execute_reply": "2021-11-20T16:08:02.960061Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg5iTGLOVfLO",
        "outputId": "0173739d-378c-479e-f880-18d9c39737c0"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.962453Z",
          "iopub.execute_input": "2021-11-20T16:08:02.962827Z",
          "iopub.status.idle": "2021-11-20T16:08:02.972323Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.962773Z",
          "shell.execute_reply": "2021-11-20T16:08:02.971548Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mF4HlbvZVfLO",
        "outputId": "4e82de37-3066-4cd5-e487-f980c0acdc33"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'etymology supplied by a late consumptive usher to a grammar school the pale usher threadbare in coat heart body and brain i see him now he'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for a in tokenizer.index_word:\n",
        "    print(a,\"--->\",tokenizer.index_word[a])\n",
        "    i+=1\n",
        "    if i==20 : break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.973894Z",
          "iopub.execute_input": "2021-11-20T16:08:02.974442Z",
          "iopub.status.idle": "2021-11-20T16:08:02.987838Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.974404Z",
          "shell.execute_reply": "2021-11-20T16:08:02.987117Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7imAHauVfLO",
        "outputId": "f773193a-3144-4cc2-a509-c8eaa97ecc5a"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 ---> the\n",
            "2 ---> and\n",
            "3 ---> of\n",
            "4 ---> a\n",
            "5 ---> to\n",
            "6 ---> in\n",
            "7 ---> i\n",
            "8 ---> that\n",
            "9 ---> his\n",
            "10 ---> he\n",
            "11 ---> it\n",
            "12 ---> was\n",
            "13 ---> but\n",
            "14 ---> with\n",
            "15 ---> 's\n",
            "16 ---> for\n",
            "17 ---> all\n",
            "18 ---> as\n",
            "19 ---> at\n",
            "20 ---> is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences[0]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.989184Z",
          "iopub.execute_input": "2021-11-20T16:08:02.989413Z",
          "iopub.status.idle": "2021-11-20T16:08:02.997522Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.989381Z",
          "shell.execute_reply": "2021-11-20T16:08:02.996651Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNy8XjxVVfLO",
        "outputId": "036e05a0-e719-48b6-a61a-b2c92530f182"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7162 : etymology\n",
            "1346 : supplied\n",
            "30 : by\n",
            "4 : a\n",
            "476 : late\n",
            "7161 : consumptive\n",
            "7157 : usher\n",
            "5 : to\n",
            "4 : a\n",
            "7160 : grammar\n",
            "1893 : school\n",
            "1 : the\n",
            "1892 : pale\n",
            "7157 : usher\n",
            "7158 : threadbare\n",
            "6 : in\n",
            "475 : coat\n",
            "276 : heart\n",
            "513 : body\n",
            "2 : and\n",
            "1891 : brain\n",
            "7 : i\n",
            "91 : see\n",
            "22 : him\n",
            "39 : now\n",
            "10 : he\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for a in tokenizer.word_counts:\n",
        "    print((a,tokenizer.word_counts[a]))\n",
        "    i+=1\n",
        "    if i==10 : break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:02.999021Z",
          "iopub.execute_input": "2021-11-20T16:08:02.999314Z",
          "iopub.status.idle": "2021-11-20T16:08:03.006324Z",
          "shell.execute_reply.started": "2021-11-20T16:08:02.999279Z",
          "shell.execute_reply": "2021-11-20T16:08:03.005521Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KZmAWkXVfLO",
        "outputId": "71481c61-e169-403c-a304-e54b2b16dbf3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('etymology', 1)\n",
            "('supplied', 80)\n",
            "('by', 4917)\n",
            "('a', 31636)\n",
            "('late', 265)\n",
            "('consumptive', 6)\n",
            "('usher', 21)\n",
            "('to', 27072)\n",
            "('grammar', 10)\n",
            "('school', 63)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)\n",
        "vocabulary_size"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.007917Z",
          "iopub.execute_input": "2021-11-20T16:08:03.008240Z",
          "iopub.status.idle": "2021-11-20T16:08:03.014738Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.008205Z",
          "shell.execute_reply": "2021-11-20T16:08:03.013857Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4oQJgX9VfLO",
        "outputId": "fe625088-7f16-45f1-ebca-b1e3e2d39d88"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7162"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=6990\n",
        "for a in range(i,7000):\n",
        "    print(a,\"--->\",tokenizer.index_word[a])\n",
        "    #i+=1\n",
        "    #if i==6999 : break"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.016305Z",
          "iopub.execute_input": "2021-11-20T16:08:03.016782Z",
          "iopub.status.idle": "2021-11-20T16:08:03.026894Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.016747Z",
          "shell.execute_reply": "2021-11-20T16:08:03.026012Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1CRHGb3VfLP",
        "outputId": "a3fb7de4-ecc3-437c-a27c-6e67efd6ac7e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6990 ---> facts\n",
            "6991 ---> triumphantly\n",
            "6992 ---> cleanliest\n",
            "6993 ---> tidy\n",
            "6994 ---> granting\n",
            "6995 ---> slippery\n",
            "6996 ---> comparable\n",
            "6997 ---> carrion\n",
            "6998 ---> soldiers\n",
            "6999 ---> plaudits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.index_word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.028313Z",
          "iopub.execute_input": "2021-11-20T16:08:03.028997Z",
          "iopub.status.idle": "2021-11-20T16:08:03.032400Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.028952Z",
          "shell.execute_reply": "2021-11-20T16:08:03.031502Z"
        },
        "trusted": true,
        "id": "CzRInpAxVfLP"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e. Convert to Numpy Matrix"
      ],
      "metadata": {
        "id": "G07Mm8BDVfLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.034222Z",
          "iopub.execute_input": "2021-11-20T16:08:03.034692Z",
          "iopub.status.idle": "2021-11-20T16:08:03.041685Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.034653Z",
          "shell.execute_reply": "2021-11-20T16:08:03.040978Z"
        },
        "trusted": true,
        "id": "2139aVUZVfLP"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.044249Z",
          "iopub.execute_input": "2021-11-20T16:08:03.045080Z",
          "iopub.status.idle": "2021-11-20T16:08:03.052295Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.045040Z",
          "shell.execute_reply": "2021-11-20T16:08:03.051485Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQIarOZJVfLP",
        "outputId": "0b77934c-0af3-40c9-9423-35ee9c70adc8"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45429"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.053958Z",
          "iopub.execute_input": "2021-11-20T16:08:03.054462Z",
          "iopub.status.idle": "2021-11-20T16:08:03.061536Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.054425Z",
          "shell.execute_reply": "2021-11-20T16:08:03.060774Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkHBQP6iVfLQ",
        "outputId": "00c86b23-7cc4-4c89-db17-44998df33693"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.063030Z",
          "iopub.execute_input": "2021-11-20T16:08:03.063361Z",
          "iopub.status.idle": "2021-11-20T16:08:03.322004Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.063303Z",
          "shell.execute_reply": "2021-11-20T16:08:03.321021Z"
        },
        "trusted": true,
        "id": "SMYpfnPxVfLQ"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.323553Z",
          "iopub.execute_input": "2021-11-20T16:08:03.323899Z",
          "iopub.status.idle": "2021-11-20T16:08:03.334371Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.323858Z",
          "shell.execute_reply": "2021-11-20T16:08:03.333651Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-J5_iBaVfLQ",
        "outputId": "bc9d0f97-b985-4c9a-c5c2-e79abee4a804"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45429, 26)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:08:03.336586Z",
          "iopub.execute_input": "2021-11-20T16:08:03.336868Z",
          "iopub.status.idle": "2021-11-20T16:08:03.343630Z",
          "shell.execute_reply.started": "2021-11-20T16:08:03.336832Z",
          "shell.execute_reply": "2021-11-20T16:08:03.342700Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26AE6FWqVfLQ",
        "outputId": "9ab94271-2394-4886-8ff3-9fd64b2c2a54"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7162, 1346,   30, ...,   22,   39,   10],\n",
              "       [1346,   30,    4, ...,   39,   10,   12],\n",
              "       [  30,    4,  476, ...,   10,   12,  133],\n",
              "       ...,\n",
              "       [   1,  373, 7156, ...,  108,   27,    1],\n",
              "       [ 373, 7156,  643, ...,   27,    1, 3012],\n",
              "       [7156,  643,    5, ...,    1, 3012,  477]])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Creating an LSTM based model"
      ],
      "metadata": {
        "id": "GRij_pm6VfLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:10:15.996834Z",
          "iopub.execute_input": "2021-11-20T16:10:15.997656Z",
          "iopub.status.idle": "2021-11-20T16:10:16.002293Z",
          "shell.execute_reply.started": "2021-11-20T16:10:15.997604Z",
          "shell.execute_reply": "2021-11-20T16:10:16.001476Z"
        },
        "trusted": true,
        "id": "AKovp_dqVfLQ"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:17:58.020073Z",
          "iopub.execute_input": "2021-11-20T16:17:58.020352Z",
          "iopub.status.idle": "2021-11-20T16:17:58.027547Z",
          "shell.execute_reply.started": "2021-11-20T16:17:58.020321Z",
          "shell.execute_reply": "2021-11-20T16:17:58.026857Z"
        },
        "trusted": true,
        "id": "mZ9eBSwNVfLQ"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train / Test Split"
      ],
      "metadata": {
        "id": "fdTJ7fmYVfLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:18:34.479096Z",
          "iopub.execute_input": "2021-11-20T16:18:34.479353Z",
          "iopub.status.idle": "2021-11-20T16:18:34.777220Z",
          "shell.execute_reply.started": "2021-11-20T16:18:34.479324Z",
          "shell.execute_reply": "2021-11-20T16:18:34.776451Z"
        },
        "trusted": true,
        "id": "mGeRDNiGVfLQ"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences.shape)\n",
        "sequences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:18:36.050428Z",
          "iopub.execute_input": "2021-11-20T16:18:36.050680Z",
          "iopub.status.idle": "2021-11-20T16:18:36.061793Z",
          "shell.execute_reply.started": "2021-11-20T16:18:36.050652Z",
          "shell.execute_reply": "2021-11-20T16:18:36.061085Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uotPut8DVfLQ",
        "outputId": "48a688a4-9bde-469c-dc99-2ce722b30499"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45429, 26)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7162, 1346,   30, ...,   22,   39,   10],\n",
              "       [1346,   30,    4, ...,   39,   10,   12],\n",
              "       [  30,    4,  476, ...,   10,   12,  133],\n",
              "       ...,\n",
              "       [   1,  373, 7156, ...,  108,   27,    1],\n",
              "       [ 373, 7156,  643, ...,   27,    1, 3012],\n",
              "       [7156,  643,    5, ...,    1, 3012,  477]])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First 25 words\n",
        "print(sequences[:,:-1].shape)\n",
        "sequences[:,:-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:23:11.975462Z",
          "iopub.execute_input": "2021-11-20T16:23:11.975713Z",
          "iopub.status.idle": "2021-11-20T16:23:11.984463Z",
          "shell.execute_reply.started": "2021-11-20T16:23:11.975682Z",
          "shell.execute_reply": "2021-11-20T16:23:11.983565Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VF13Lb-YVfLQ",
        "outputId": "12b77bea-fcd7-4c3d-ed5a-5bccbba59693"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45429, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7162, 1346,   30, ...,   91,   22,   39],\n",
              "       [1346,   30,    4, ...,   22,   39,   10],\n",
              "       [  30,    4,  476, ...,   39,   10,   12],\n",
              "       ...,\n",
              "       [   1,  373, 7156, ...,    1,  108,   27],\n",
              "       [ 373, 7156,  643, ...,  108,   27,    1],\n",
              "       [7156,  643,    5, ...,   27,    1, 3012]])"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last Word\n",
        "print(sequences[:,-1].shape)\n",
        "sequences[:,-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:23:00.016191Z",
          "iopub.execute_input": "2021-11-20T16:23:00.016887Z",
          "iopub.status.idle": "2021-11-20T16:23:00.022703Z",
          "shell.execute_reply.started": "2021-11-20T16:23:00.016854Z",
          "shell.execute_reply": "2021-11-20T16:23:00.021855Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbCkQB53VfLR",
        "outputId": "13d4282e-6c72-4f7f-9b1c-e1236ddc07c8"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45429,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  10,   12,  133, ...,    1, 3012,  477])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = sequences[:,:-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:23:51.629952Z",
          "iopub.execute_input": "2021-11-20T16:23:51.630727Z",
          "iopub.status.idle": "2021-11-20T16:23:51.635126Z",
          "shell.execute_reply.started": "2021-11-20T16:23:51.630672Z",
          "shell.execute_reply": "2021-11-20T16:23:51.634058Z"
        },
        "trusted": true,
        "id": "vT9uM1GyVfLR"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:23:53.753357Z",
          "iopub.execute_input": "2021-11-20T16:23:53.753631Z",
          "iopub.status.idle": "2021-11-20T16:23:53.759122Z",
          "shell.execute_reply.started": "2021-11-20T16:23:53.753600Z",
          "shell.execute_reply": "2021-11-20T16:23:53.758391Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewtKrIqNVfLR",
        "outputId": "ea4ce6cf-528a-445b-e2d4-df8c88750f7e"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45429, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = sequences[:,-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:23:57.195456Z",
          "iopub.execute_input": "2021-11-20T16:23:57.196232Z",
          "iopub.status.idle": "2021-11-20T16:23:57.200928Z",
          "shell.execute_reply.started": "2021-11-20T16:23:57.196179Z",
          "shell.execute_reply": "2021-11-20T16:23:57.199912Z"
        },
        "trusted": true,
        "id": "w3ZGLGGlVfLR"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:03.132095Z",
          "iopub.execute_input": "2021-11-20T16:24:03.132757Z",
          "iopub.status.idle": "2021-11-20T16:24:03.138687Z",
          "shell.execute_reply.started": "2021-11-20T16:24:03.132705Z",
          "shell.execute_reply": "2021-11-20T16:24:03.137918Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB859lfhVfLR",
        "outputId": "962e9240-e6c0-4957-885a-0130528d5599"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45429,)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y, num_classes=vocabulary_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:10.297076Z",
          "iopub.execute_input": "2021-11-20T16:24:10.297574Z",
          "iopub.status.idle": "2021-11-20T16:24:10.393855Z",
          "shell.execute_reply.started": "2021-11-20T16:24:10.297533Z",
          "shell.execute_reply": "2021-11-20T16:24:10.393066Z"
        },
        "trusted": true,
        "id": "cyEmB3MuVfLR"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:12.700098Z",
          "iopub.execute_input": "2021-11-20T16:24:12.700741Z",
          "iopub.status.idle": "2021-11-20T16:24:12.706859Z",
          "shell.execute_reply.started": "2021-11-20T16:24:12.700698Z",
          "shell.execute_reply": "2021-11-20T16:24:12.705941Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAZefPB1VfLR",
        "outputId": "0223fc7b-2128-4f65-88d1-2e90be93e972"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45429, 7162)"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = X.shape[1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:42.435572Z",
          "iopub.execute_input": "2021-11-20T16:24:42.436120Z",
          "iopub.status.idle": "2021-11-20T16:24:42.439740Z",
          "shell.execute_reply.started": "2021-11-20T16:24:42.436080Z",
          "shell.execute_reply": "2021-11-20T16:24:42.438762Z"
        },
        "trusted": true,
        "id": "13d_1gN3VfLR"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:43.818788Z",
          "iopub.execute_input": "2021-11-20T16:24:43.819357Z",
          "iopub.status.idle": "2021-11-20T16:24:43.825152Z",
          "shell.execute_reply.started": "2021-11-20T16:24:43.819317Z",
          "shell.execute_reply": "2021-11-20T16:24:43.824218Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9EiP_hUVfLR",
        "outputId": "8ce3c3c7-66cd-4fb1-c316-da469fe2826a"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Training the Model"
      ],
      "metadata": {
        "id": "iI-wOLkxVfLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = create_model(vocabulary_size, seq_len)\n",
        "#model = create_model(vocabulary_size, seq_len)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:24:57.008986Z",
          "iopub.execute_input": "2021-11-20T16:24:57.009651Z",
          "iopub.status.idle": "2021-11-20T16:25:04.816192Z",
          "shell.execute_reply.started": "2021-11-20T16:24:57.009613Z",
          "shell.execute_reply": "2021-11-20T16:25:04.815470Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-OWkDn1VfLR",
        "outputId": "625e7638-ca1c-4703-d211-3fa1f99723f6"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 25, 25)            179050    \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 25, 150)           105600    \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 150)               22650     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 7162)              1081462   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1569362 (5.99 MB)\n",
            "Trainable params: 1569362 (5.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "Jd4WjBb0VfLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Fit model"
      ],
      "metadata": {
        "id": "O3HHDHj4VfLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, batch_size=512, epochs=250,verbose=1,validation_batch_size=.20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:26:25.287630Z",
          "iopub.execute_input": "2021-11-20T16:26:25.288463Z",
          "iopub.status.idle": "2021-11-20T16:35:52.361595Z",
          "shell.execute_reply.started": "2021-11-20T16:26:25.288414Z",
          "shell.execute_reply": "2021-11-20T16:35:52.360782Z"
        },
        "scrolled": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx9b_651VfLS",
        "outputId": "0a06f256-af92-44f8-e247-ff11eaad7fc5"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "89/89 [==============================] - 17s 146ms/step - loss: 7.2786 - accuracy: 0.0483\n",
            "Epoch 2/250\n",
            "89/89 [==============================] - 8s 92ms/step - loss: 6.7628 - accuracy: 0.0554\n",
            "Epoch 3/250\n",
            "89/89 [==============================] - 7s 79ms/step - loss: 6.7418 - accuracy: 0.0554\n",
            "Epoch 4/250\n",
            "89/89 [==============================] - 6s 64ms/step - loss: 6.6454 - accuracy: 0.0554\n",
            "Epoch 5/250\n",
            "89/89 [==============================] - 4s 47ms/step - loss: 6.5197 - accuracy: 0.0565\n",
            "Epoch 6/250\n",
            "89/89 [==============================] - 4s 40ms/step - loss: 6.3964 - accuracy: 0.0627\n",
            "Epoch 7/250\n",
            "89/89 [==============================] - 4s 46ms/step - loss: 6.3057 - accuracy: 0.0704\n",
            "Epoch 8/250\n",
            "89/89 [==============================] - 3s 37ms/step - loss: 6.2412 - accuracy: 0.0727\n",
            "Epoch 9/250\n",
            "89/89 [==============================] - 3s 36ms/step - loss: 6.1849 - accuracy: 0.0745\n",
            "Epoch 10/250\n",
            "89/89 [==============================] - 5s 49ms/step - loss: 6.1318 - accuracy: 0.0772\n",
            "Epoch 11/250\n",
            "89/89 [==============================] - 3s 39ms/step - loss: 6.0815 - accuracy: 0.0789\n",
            "Epoch 12/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 6.0330 - accuracy: 0.0809\n",
            "Epoch 13/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 5.9899 - accuracy: 0.0820\n",
            "Epoch 14/250\n",
            "89/89 [==============================] - 3s 38ms/step - loss: 5.9467 - accuracy: 0.0836\n",
            "Epoch 15/250\n",
            "89/89 [==============================] - 3s 35ms/step - loss: 5.9056 - accuracy: 0.0852\n",
            "Epoch 16/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 5.8661 - accuracy: 0.0856\n",
            "Epoch 17/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 5.8240 - accuracy: 0.0870\n",
            "Epoch 18/250\n",
            "89/89 [==============================] - 3s 38ms/step - loss: 5.7828 - accuracy: 0.0891\n",
            "Epoch 19/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 5.7406 - accuracy: 0.0904\n",
            "Epoch 20/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 5.6941 - accuracy: 0.0914\n",
            "Epoch 21/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 5.6461 - accuracy: 0.0928\n",
            "Epoch 22/250\n",
            "89/89 [==============================] - 3s 39ms/step - loss: 5.5970 - accuracy: 0.0943\n",
            "Epoch 23/250\n",
            "89/89 [==============================] - 3s 36ms/step - loss: 5.5478 - accuracy: 0.0969\n",
            "Epoch 24/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 5.5008 - accuracy: 0.0970\n",
            "Epoch 25/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 5.4464 - accuracy: 0.1005\n",
            "Epoch 26/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 5.3999 - accuracy: 0.1010\n",
            "Epoch 27/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 5.3480 - accuracy: 0.1030\n",
            "Epoch 28/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 5.2991 - accuracy: 0.1055\n",
            "Epoch 29/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 5.2517 - accuracy: 0.1067\n",
            "Epoch 30/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 5.2052 - accuracy: 0.1089\n",
            "Epoch 31/250\n",
            "89/89 [==============================] - 3s 37ms/step - loss: 5.1616 - accuracy: 0.1105\n",
            "Epoch 32/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 5.1196 - accuracy: 0.1122\n",
            "Epoch 33/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 5.0785 - accuracy: 0.1144\n",
            "Epoch 34/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 5.0386 - accuracy: 0.1155\n",
            "Epoch 35/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 4.9978 - accuracy: 0.1170\n",
            "Epoch 36/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 4.9601 - accuracy: 0.1183\n",
            "Epoch 37/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.9237 - accuracy: 0.1179\n",
            "Epoch 38/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 4.8885 - accuracy: 0.1210\n",
            "Epoch 39/250\n",
            "89/89 [==============================] - 3s 35ms/step - loss: 4.8527 - accuracy: 0.1221\n",
            "Epoch 40/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 4.8170 - accuracy: 0.1229\n",
            "Epoch 41/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 5.1570 - accuracy: 0.1114\n",
            "Epoch 42/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 5.3930 - accuracy: 0.1026\n",
            "Epoch 43/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 5.0072 - accuracy: 0.1154\n",
            "Epoch 44/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 4.8572 - accuracy: 0.1204\n",
            "Epoch 45/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 4.7792 - accuracy: 0.1245\n",
            "Epoch 46/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 4.7224 - accuracy: 0.1269\n",
            "Epoch 47/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 4.6721 - accuracy: 0.1292\n",
            "Epoch 48/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 4.6282 - accuracy: 0.1312\n",
            "Epoch 49/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 4.5832 - accuracy: 0.1332\n",
            "Epoch 50/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 4.5425 - accuracy: 0.1359\n",
            "Epoch 51/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 4.4953 - accuracy: 0.1388\n",
            "Epoch 52/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.4477 - accuracy: 0.1422\n",
            "Epoch 53/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 4.4041 - accuracy: 0.1458\n",
            "Epoch 54/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.3550 - accuracy: 0.1499\n",
            "Epoch 55/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.3072 - accuracy: 0.1529\n",
            "Epoch 56/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.2613 - accuracy: 0.1565\n",
            "Epoch 57/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.2133 - accuracy: 0.1599\n",
            "Epoch 58/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 4.1679 - accuracy: 0.1635\n",
            "Epoch 59/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.1144 - accuracy: 0.1697\n",
            "Epoch 60/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 4.0683 - accuracy: 0.1739\n",
            "Epoch 61/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 4.0234 - accuracy: 0.1798\n",
            "Epoch 62/250\n",
            "89/89 [==============================] - 3s 36ms/step - loss: 3.9747 - accuracy: 0.1841\n",
            "Epoch 63/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 3.9242 - accuracy: 0.1903\n",
            "Epoch 64/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.8741 - accuracy: 0.1976\n",
            "Epoch 65/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 3.8228 - accuracy: 0.2043\n",
            "Epoch 66/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.7771 - accuracy: 0.2109\n",
            "Epoch 67/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.7352 - accuracy: 0.2159\n",
            "Epoch 68/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 3.6945 - accuracy: 0.2226\n",
            "Epoch 69/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 3.6450 - accuracy: 0.2286\n",
            "Epoch 70/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.5969 - accuracy: 0.2366\n",
            "Epoch 71/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 3.5567 - accuracy: 0.2435\n",
            "Epoch 72/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 3.5158 - accuracy: 0.2487\n",
            "Epoch 73/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 3.4719 - accuracy: 0.2570\n",
            "Epoch 74/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.4299 - accuracy: 0.2633\n",
            "Epoch 75/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 3.3881 - accuracy: 0.2708\n",
            "Epoch 76/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 3.3466 - accuracy: 0.2776\n",
            "Epoch 77/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 3.3077 - accuracy: 0.2840\n",
            "Epoch 78/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 3.2693 - accuracy: 0.2900\n",
            "Epoch 79/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 3.2344 - accuracy: 0.2978\n",
            "Epoch 80/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 3.1930 - accuracy: 0.3044\n",
            "Epoch 81/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.1548 - accuracy: 0.3096\n",
            "Epoch 82/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 3.1189 - accuracy: 0.3180\n",
            "Epoch 83/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 3.0816 - accuracy: 0.3231\n",
            "Epoch 84/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.0485 - accuracy: 0.3295\n",
            "Epoch 85/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 3.0116 - accuracy: 0.3366\n",
            "Epoch 86/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 2.9778 - accuracy: 0.3430\n",
            "Epoch 87/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.9474 - accuracy: 0.3470\n",
            "Epoch 88/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.9123 - accuracy: 0.3528\n",
            "Epoch 89/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 2.8785 - accuracy: 0.3593\n",
            "Epoch 90/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 2.8465 - accuracy: 0.3659\n",
            "Epoch 91/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.8186 - accuracy: 0.3723\n",
            "Epoch 92/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.7858 - accuracy: 0.3776\n",
            "Epoch 93/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 2.7576 - accuracy: 0.3817\n",
            "Epoch 94/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.7322 - accuracy: 0.3879\n",
            "Epoch 95/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.7051 - accuracy: 0.3926\n",
            "Epoch 96/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 2.6744 - accuracy: 0.3968\n",
            "Epoch 97/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.6455 - accuracy: 0.4033\n",
            "Epoch 98/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 2.6173 - accuracy: 0.4080\n",
            "Epoch 99/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 2.5906 - accuracy: 0.4132\n",
            "Epoch 100/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.5662 - accuracy: 0.4179\n",
            "Epoch 101/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.5399 - accuracy: 0.4220\n",
            "Epoch 102/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.5167 - accuracy: 0.4264\n",
            "Epoch 103/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 2.4894 - accuracy: 0.4336\n",
            "Epoch 104/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.4645 - accuracy: 0.4366\n",
            "Epoch 105/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.4402 - accuracy: 0.4415\n",
            "Epoch 106/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.4163 - accuracy: 0.4445\n",
            "Epoch 107/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.3969 - accuracy: 0.4503\n",
            "Epoch 108/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.7342 - accuracy: 0.3972\n",
            "Epoch 109/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 2.5060 - accuracy: 0.4200\n",
            "Epoch 110/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.3847 - accuracy: 0.4512\n",
            "Epoch 111/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.3393 - accuracy: 0.4604\n",
            "Epoch 112/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.3077 - accuracy: 0.4671\n",
            "Epoch 113/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.2810 - accuracy: 0.4742\n",
            "Epoch 114/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 2.2594 - accuracy: 0.4772\n",
            "Epoch 115/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 2.2367 - accuracy: 0.4817\n",
            "Epoch 116/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 2.2182 - accuracy: 0.4857\n",
            "Epoch 117/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.1969 - accuracy: 0.4895\n",
            "Epoch 118/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 2.1758 - accuracy: 0.4939\n",
            "Epoch 119/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.1580 - accuracy: 0.4976\n",
            "Epoch 120/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 2.1383 - accuracy: 0.5020\n",
            "Epoch 121/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 2.1193 - accuracy: 0.5049\n",
            "Epoch 122/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.1044 - accuracy: 0.5082\n",
            "Epoch 123/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 2.0813 - accuracy: 0.5108\n",
            "Epoch 124/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 2.0727 - accuracy: 0.5127\n",
            "Epoch 125/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 2.0458 - accuracy: 0.5191\n",
            "Epoch 126/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.0286 - accuracy: 0.5243\n",
            "Epoch 127/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 2.0070 - accuracy: 0.5279\n",
            "Epoch 128/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.9909 - accuracy: 0.5320\n",
            "Epoch 129/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.9729 - accuracy: 0.5360\n",
            "Epoch 130/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.9565 - accuracy: 0.5364\n",
            "Epoch 131/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.9369 - accuracy: 0.5437\n",
            "Epoch 132/250\n",
            "89/89 [==============================] - 3s 34ms/step - loss: 1.9230 - accuracy: 0.5445\n",
            "Epoch 133/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.9058 - accuracy: 0.5486\n",
            "Epoch 134/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.8889 - accuracy: 0.5517\n",
            "Epoch 135/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.8727 - accuracy: 0.5569\n",
            "Epoch 136/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.8519 - accuracy: 0.5597\n",
            "Epoch 137/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.8317 - accuracy: 0.5638\n",
            "Epoch 138/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.8197 - accuracy: 0.5665\n",
            "Epoch 139/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.8034 - accuracy: 0.5701\n",
            "Epoch 140/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.7891 - accuracy: 0.5736\n",
            "Epoch 141/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.7764 - accuracy: 0.5751\n",
            "Epoch 142/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.7538 - accuracy: 0.5819\n",
            "Epoch 143/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.7356 - accuracy: 0.5858\n",
            "Epoch 144/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.7219 - accuracy: 0.5856\n",
            "Epoch 145/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.7080 - accuracy: 0.5892\n",
            "Epoch 146/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.6851 - accuracy: 0.5952\n",
            "Epoch 147/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.6752 - accuracy: 0.5988\n",
            "Epoch 148/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.6592 - accuracy: 0.6027\n",
            "Epoch 149/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.6453 - accuracy: 0.6041\n",
            "Epoch 150/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.6240 - accuracy: 0.6085\n",
            "Epoch 151/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.6108 - accuracy: 0.6116\n",
            "Epoch 152/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.5987 - accuracy: 0.6142\n",
            "Epoch 153/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.5828 - accuracy: 0.6183\n",
            "Epoch 154/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.5759 - accuracy: 0.6187\n",
            "Epoch 155/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.5523 - accuracy: 0.6259\n",
            "Epoch 156/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.5358 - accuracy: 0.6287\n",
            "Epoch 157/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.5135 - accuracy: 0.6339\n",
            "Epoch 158/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.5048 - accuracy: 0.6360\n",
            "Epoch 159/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.4923 - accuracy: 0.6391\n",
            "Epoch 160/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.4767 - accuracy: 0.6411\n",
            "Epoch 161/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.4569 - accuracy: 0.6466\n",
            "Epoch 162/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.4424 - accuracy: 0.6487\n",
            "Epoch 163/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.4274 - accuracy: 0.6535\n",
            "Epoch 164/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.4150 - accuracy: 0.6562\n",
            "Epoch 165/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.4024 - accuracy: 0.6590\n",
            "Epoch 166/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.3853 - accuracy: 0.6629\n",
            "Epoch 167/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.3772 - accuracy: 0.6642\n",
            "Epoch 168/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.3703 - accuracy: 0.6657\n",
            "Epoch 169/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.3471 - accuracy: 0.6707\n",
            "Epoch 170/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.3278 - accuracy: 0.6765\n",
            "Epoch 171/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.3095 - accuracy: 0.6829\n",
            "Epoch 172/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.2960 - accuracy: 0.6829\n",
            "Epoch 173/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.2796 - accuracy: 0.6875\n",
            "Epoch 174/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 1.2719 - accuracy: 0.6893\n",
            "Epoch 175/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 1.2544 - accuracy: 0.6929\n",
            "Epoch 176/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.2398 - accuracy: 0.6988\n",
            "Epoch 177/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.2225 - accuracy: 0.7018\n",
            "Epoch 178/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.2167 - accuracy: 0.7016\n",
            "Epoch 179/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.1959 - accuracy: 0.7088\n",
            "Epoch 180/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.1799 - accuracy: 0.7122\n",
            "Epoch 181/250\n",
            "89/89 [==============================] - 3s 28ms/step - loss: 1.1684 - accuracy: 0.7156\n",
            "Epoch 182/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.1503 - accuracy: 0.7195\n",
            "Epoch 183/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.1381 - accuracy: 0.7227\n",
            "Epoch 184/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.1260 - accuracy: 0.7251\n",
            "Epoch 185/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.1150 - accuracy: 0.7290\n",
            "Epoch 186/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.1119 - accuracy: 0.7287\n",
            "Epoch 187/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 1.1087 - accuracy: 0.7278\n",
            "Epoch 188/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.0796 - accuracy: 0.7380\n",
            "Epoch 189/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 1.0572 - accuracy: 0.7420\n",
            "Epoch 190/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 1.0413 - accuracy: 0.7465\n",
            "Epoch 191/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.0275 - accuracy: 0.7520\n",
            "Epoch 192/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 1.0215 - accuracy: 0.7506\n",
            "Epoch 193/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.0102 - accuracy: 0.7533\n",
            "Epoch 194/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.9959 - accuracy: 0.7585\n",
            "Epoch 195/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.9822 - accuracy: 0.7613\n",
            "Epoch 196/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.9721 - accuracy: 0.7650\n",
            "Epoch 197/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.9573 - accuracy: 0.7665\n",
            "Epoch 198/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.9420 - accuracy: 0.7721\n",
            "Epoch 199/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.9421 - accuracy: 0.7700\n",
            "Epoch 200/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.9306 - accuracy: 0.7727\n",
            "Epoch 201/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.9027 - accuracy: 0.7823\n",
            "Epoch 202/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.8877 - accuracy: 0.7870\n",
            "Epoch 203/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.8828 - accuracy: 0.7859\n",
            "Epoch 204/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.8703 - accuracy: 0.7888\n",
            "Epoch 205/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.8620 - accuracy: 0.7902\n",
            "Epoch 206/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.8487 - accuracy: 0.7963\n",
            "Epoch 207/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.8350 - accuracy: 0.7989\n",
            "Epoch 208/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.8288 - accuracy: 0.7989\n",
            "Epoch 209/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.8071 - accuracy: 0.8051\n",
            "Epoch 210/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.7902 - accuracy: 0.8099\n",
            "Epoch 211/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.7801 - accuracy: 0.8117\n",
            "Epoch 212/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.7760 - accuracy: 0.8132\n",
            "Epoch 213/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.7699 - accuracy: 0.8147\n",
            "Epoch 214/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.7547 - accuracy: 0.8197\n",
            "Epoch 215/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.7407 - accuracy: 0.8227\n",
            "Epoch 216/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.7331 - accuracy: 0.8238\n",
            "Epoch 217/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.7264 - accuracy: 0.8231\n",
            "Epoch 218/250\n",
            "89/89 [==============================] - 3s 28ms/step - loss: 0.7191 - accuracy: 0.8278\n",
            "Epoch 219/250\n",
            "89/89 [==============================] - 3s 27ms/step - loss: 0.7036 - accuracy: 0.8310\n",
            "Epoch 220/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.6913 - accuracy: 0.8339\n",
            "Epoch 221/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 0.6828 - accuracy: 0.8367\n",
            "Epoch 222/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.6700 - accuracy: 0.8399\n",
            "Epoch 223/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.6525 - accuracy: 0.8447\n",
            "Epoch 224/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 0.6455 - accuracy: 0.8461\n",
            "Epoch 225/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.6351 - accuracy: 0.8494\n",
            "Epoch 226/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.6245 - accuracy: 0.8526\n",
            "Epoch 227/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.6205 - accuracy: 0.8534\n",
            "Epoch 228/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.6494 - accuracy: 0.8415\n",
            "Epoch 229/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.6351 - accuracy: 0.8472\n",
            "Epoch 230/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.6114 - accuracy: 0.8541\n",
            "Epoch 231/250\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.5830 - accuracy: 0.8634\n",
            "Epoch 232/250\n",
            "89/89 [==============================] - 3s 28ms/step - loss: 0.5625 - accuracy: 0.8702\n",
            "Epoch 233/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.5497 - accuracy: 0.8732\n",
            "Epoch 234/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.5402 - accuracy: 0.8762\n",
            "Epoch 235/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.5316 - accuracy: 0.8787\n",
            "Epoch 236/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.5292 - accuracy: 0.8781\n",
            "Epoch 237/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.5236 - accuracy: 0.8783\n",
            "Epoch 238/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.5106 - accuracy: 0.8831\n",
            "Epoch 239/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.5076 - accuracy: 0.8858\n",
            "Epoch 240/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.4923 - accuracy: 0.8887\n",
            "Epoch 241/250\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.4882 - accuracy: 0.8895\n",
            "Epoch 242/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.4821 - accuracy: 0.8911\n",
            "Epoch 243/250\n",
            "89/89 [==============================] - 2s 27ms/step - loss: 0.4700 - accuracy: 0.8946\n",
            "Epoch 244/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.4665 - accuracy: 0.8944\n",
            "Epoch 245/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.4617 - accuracy: 0.8959\n",
            "Epoch 246/250\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 0.4601 - accuracy: 0.8961\n",
            "Epoch 247/250\n",
            "89/89 [==============================] - 3s 28ms/step - loss: 0.4465 - accuracy: 0.8991\n",
            "Epoch 248/250\n",
            "89/89 [==============================] - 3s 29ms/step - loss: 0.4413 - accuracy: 0.8996\n",
            "Epoch 249/250\n",
            "89/89 [==============================] - 2s 28ms/step - loss: 0.4440 - accuracy: 0.8987\n",
            "Epoch 250/250\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 0.4336 - accuracy: 0.9021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbpCPlR_cSWj",
        "outputId": "b6bc424b-c245-4b81-ba33-f3a8bd9c175f"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04829514026641846,\n",
              " 0.05544916167855263,\n",
              " 0.05544916167855263,\n",
              " 0.05544916167855263,\n",
              " 0.05654978007078171,\n",
              " 0.06271324306726456,\n",
              " 0.07035154104232788,\n",
              " 0.07268484681844711,\n",
              " 0.07446785271167755,\n",
              " 0.0772193968296051,\n",
              " 0.0789143517613411,\n",
              " 0.08091747760772705,\n",
              " 0.08197406679391861,\n",
              " 0.08358097076416016,\n",
              " 0.08523190021514893,\n",
              " 0.08562812209129333,\n",
              " 0.08701489865779877,\n",
              " 0.08908406645059586,\n",
              " 0.09038279205560684,\n",
              " 0.09135133773088455,\n",
              " 0.09280415624380112,\n",
              " 0.09434501826763153,\n",
              " 0.09689845889806747,\n",
              " 0.09700851887464523,\n",
              " 0.10050848871469498,\n",
              " 0.10101477056741714,\n",
              " 0.10297387093305588,\n",
              " 0.105483278632164,\n",
              " 0.10669396072626114,\n",
              " 0.10885117202997208,\n",
              " 0.11045807600021362,\n",
              " 0.11219705641269684,\n",
              " 0.11435426771640778,\n",
              " 0.115542933344841,\n",
              " 0.11701776087284088,\n",
              " 0.11831649392843246,\n",
              " 0.11794228106737137,\n",
              " 0.1210460290312767,\n",
              " 0.12214664369821548,\n",
              " 0.12285104393959045,\n",
              " 0.11144863069057465,\n",
              " 0.10259965807199478,\n",
              " 0.11543287336826324,\n",
              " 0.12042967975139618,\n",
              " 0.12454599142074585,\n",
              " 0.1269453465938568,\n",
              " 0.1291906088590622,\n",
              " 0.13119372725486755,\n",
              " 0.1331528276205063,\n",
              " 0.13590437173843384,\n",
              " 0.13881000876426697,\n",
              " 0.14224393665790558,\n",
              " 0.14576591551303864,\n",
              " 0.149860218167305,\n",
              " 0.15285390615463257,\n",
              " 0.1565079540014267,\n",
              " 0.159919872879982,\n",
              " 0.16346386075019836,\n",
              " 0.16969336569309235,\n",
              " 0.17391973733901978,\n",
              " 0.17975302040576935,\n",
              " 0.18411147594451904,\n",
              " 0.19025291502475739,\n",
              " 0.19760505855083466,\n",
              " 0.20429681241512299,\n",
              " 0.21085649728775024,\n",
              " 0.21587532758712769,\n",
              " 0.22263312339782715,\n",
              " 0.22857646644115448,\n",
              " 0.2365889698266983,\n",
              " 0.24354487657546997,\n",
              " 0.24867375195026398,\n",
              " 0.2570384442806244,\n",
              " 0.26326796412467957,\n",
              " 0.2707521617412567,\n",
              " 0.2775980234146118,\n",
              " 0.2840256094932556,\n",
              " 0.28999096155166626,\n",
              " 0.29778334498405457,\n",
              " 0.30443108081817627,\n",
              " 0.3096480369567871,\n",
              " 0.31803473830223083,\n",
              " 0.32314160466194153,\n",
              " 0.3295471966266632,\n",
              " 0.33663520216941833,\n",
              " 0.3429747521877289,\n",
              " 0.3469809889793396,\n",
              " 0.35281428694725037,\n",
              " 0.3593299388885498,\n",
              " 0.36586761474609375,\n",
              " 0.37233924865722656,\n",
              " 0.3775781989097595,\n",
              " 0.3817165195941925,\n",
              " 0.3879460394382477,\n",
              " 0.39263466000556946,\n",
              " 0.39677298069000244,\n",
              " 0.4033106565475464,\n",
              " 0.40802130103111267,\n",
              " 0.4132382273674011,\n",
              " 0.4179268777370453,\n",
              " 0.42204317450523376,\n",
              " 0.4264236390590668,\n",
              " 0.43362170457839966,\n",
              " 0.43659335374832153,\n",
              " 0.4415241479873657,\n",
              " 0.4444738030433655,\n",
              " 0.45030707120895386,\n",
              " 0.3972132205963135,\n",
              " 0.4200180470943451,\n",
              " 0.4511655569076538,\n",
              " 0.4604107439517975,\n",
              " 0.4670584797859192,\n",
              " 0.47419050335884094,\n",
              " 0.4771841764450073,\n",
              " 0.4816967248916626,\n",
              " 0.4856809675693512,\n",
              " 0.48953312635421753,\n",
              " 0.49391359090805054,\n",
              " 0.4976116716861725,\n",
              " 0.5020361542701721,\n",
              " 0.5049197673797607,\n",
              " 0.5081555843353271,\n",
              " 0.5107750296592712,\n",
              " 0.5126901268959045,\n",
              " 0.5191177725791931,\n",
              " 0.5243346691131592,\n",
              " 0.5279006958007812,\n",
              " 0.5319949984550476,\n",
              " 0.5359792113304138,\n",
              " 0.5364194512367249,\n",
              " 0.5436615347862244,\n",
              " 0.5445200204849243,\n",
              " 0.5486143231391907,\n",
              " 0.5516740679740906,\n",
              " 0.5568689703941345,\n",
              " 0.559686541557312,\n",
              " 0.5637588500976562,\n",
              " 0.5665323734283447,\n",
              " 0.5701203942298889,\n",
              " 0.573642373085022,\n",
              " 0.5751172304153442,\n",
              " 0.5818970203399658,\n",
              " 0.5857712030410767,\n",
              " 0.5855510830879211,\n",
              " 0.5891610980033875,\n",
              " 0.5951924920082092,\n",
              " 0.5988245606422424,\n",
              " 0.6026546955108643,\n",
              " 0.6040855050086975,\n",
              " 0.6084659695625305,\n",
              " 0.6116357445716858,\n",
              " 0.6141891479492188,\n",
              " 0.618261456489563,\n",
              " 0.618701696395874,\n",
              " 0.6258777379989624,\n",
              " 0.6287173628807068,\n",
              " 0.6338902711868286,\n",
              " 0.6360474824905396,\n",
              " 0.6390851736068726,\n",
              " 0.6410662531852722,\n",
              " 0.6465913653373718,\n",
              " 0.6486825346946716,\n",
              " 0.6534812450408936,\n",
              " 0.6562107801437378,\n",
              " 0.658984363079071,\n",
              " 0.6629465818405151,\n",
              " 0.664223313331604,\n",
              " 0.6656761169433594,\n",
              " 0.670738935470581,\n",
              " 0.6764841675758362,\n",
              " 0.6829338073730469,\n",
              " 0.6828897595405579,\n",
              " 0.6874683499336243,\n",
              " 0.6892954111099243,\n",
              " 0.6928833723068237,\n",
              " 0.6988267302513123,\n",
              " 0.701820433139801,\n",
              " 0.7015782594680786,\n",
              " 0.7087763547897339,\n",
              " 0.7121662497520447,\n",
              " 0.7155781388282776,\n",
              " 0.7194963693618774,\n",
              " 0.7226881384849548,\n",
              " 0.7250654697418213,\n",
              " 0.7290056943893433,\n",
              " 0.7287195324897766,\n",
              " 0.7278170585632324,\n",
              " 0.7380307912826538,\n",
              " 0.7420369982719421,\n",
              " 0.7465495467185974,\n",
              " 0.7519646286964417,\n",
              " 0.7505998611450195,\n",
              " 0.7532853484153748,\n",
              " 0.7585462927818298,\n",
              " 0.7613418698310852,\n",
              " 0.7650179266929626,\n",
              " 0.7664927840232849,\n",
              " 0.7720618844032288,\n",
              " 0.7700367569923401,\n",
              " 0.772656261920929,\n",
              " 0.782253623008728,\n",
              " 0.7869642972946167,\n",
              " 0.7858636379241943,\n",
              " 0.788835346698761,\n",
              " 0.7901560664176941,\n",
              " 0.7963195443153381,\n",
              " 0.798895001411438,\n",
              " 0.7989169955253601,\n",
              " 0.8050804734230042,\n",
              " 0.8098571300506592,\n",
              " 0.8117061853408813,\n",
              " 0.8132030367851257,\n",
              " 0.8146998882293701,\n",
              " 0.8197407126426697,\n",
              " 0.8227343559265137,\n",
              " 0.823835015296936,\n",
              " 0.8231086134910583,\n",
              " 0.8278192281723022,\n",
              " 0.8309670090675354,\n",
              " 0.8339166641235352,\n",
              " 0.8367342352867126,\n",
              " 0.8399480581283569,\n",
              " 0.8446586728096008,\n",
              " 0.8461335301399231,\n",
              " 0.8493693470954895,\n",
              " 0.8525611162185669,\n",
              " 0.8533976078033447,\n",
              " 0.8415329456329346,\n",
              " 0.8472341299057007,\n",
              " 0.8541240096092224,\n",
              " 0.8634132146835327,\n",
              " 0.8701930642127991,\n",
              " 0.8732307553291321,\n",
              " 0.876202404499054,\n",
              " 0.8786678314208984,\n",
              " 0.8780514597892761,\n",
              " 0.8783376216888428,\n",
              " 0.8831363320350647,\n",
              " 0.8858438730239868,\n",
              " 0.8886614441871643,\n",
              " 0.8895199298858643,\n",
              " 0.891082763671875,\n",
              " 0.894626796245575,\n",
              " 0.8944066762924194,\n",
              " 0.895903468132019,\n",
              " 0.8960576057434082,\n",
              " 0.8990733027458191,\n",
              " 0.8995795845985413,\n",
              " 0.8986770510673523,\n",
              " 0.9021329879760742]"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Model Object"
      ],
      "metadata": {
        "id": "tYKegYvxVfLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump,load"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:36:24.974328Z",
          "iopub.execute_input": "2021-11-20T16:36:24.975060Z",
          "iopub.status.idle": "2021-11-20T16:36:24.979192Z",
          "shell.execute_reply.started": "2021-11-20T16:36:24.975020Z",
          "shell.execute_reply": "2021-11-20T16:36:24.978045Z"
        },
        "trusted": true,
        "id": "cCgUUxb8VfLS"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to file\n",
        "model.save('epochBIG.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('epochBIG', 'wb'))"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2021-11-20T16:36:26.302455Z",
          "iopub.execute_input": "2021-11-20T16:36:26.302742Z",
          "iopub.status.idle": "2021-11-20T16:36:26.383659Z",
          "shell.execute_reply.started": "2021-11-20T16:36:26.302709Z",
          "shell.execute_reply": "2021-11-20T16:36:26.382891Z"
        },
        "trusted": true,
        "id": "ciN0GNyTVfLS"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generating New Text"
      ],
      "metadata": {
        "id": "t99drZUrVfLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:36:52.786375Z",
          "iopub.execute_input": "2021-11-20T16:36:52.786654Z",
          "iopub.status.idle": "2021-11-20T16:36:52.791214Z",
          "shell.execute_reply.started": "2021-11-20T16:36:52.786620Z",
          "shell.execute_reply": "2021-11-20T16:36:52.790094Z"
        },
        "trusted": true,
        "id": "0DwOOaABVfLS"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "\n",
        "    # Final Output\n",
        "    output_text = []\n",
        "\n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "\n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "\n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "\n",
        "        # Pad sequences to our trained rate (25 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "\n",
        "        # Predict Class Probabilities for each word\n",
        "        #pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
        "        predict_x=model.predict(pad_encoded)\n",
        "        pred_word_ind=np.argmax(predict_x,axis=1)[0]\n",
        "        #print(pred_word_ind)\n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind]\n",
        "\n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "\n",
        "        output_text.append(pred_word)\n",
        "\n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:16.771265Z",
          "iopub.execute_input": "2021-11-20T16:37:16.771678Z",
          "iopub.status.idle": "2021-11-20T16:37:16.782743Z",
          "shell.execute_reply.started": "2021-11-20T16:37:16.771633Z",
          "shell.execute_reply": "2021-11-20T16:37:16.781849Z"
        },
        "trusted": true,
        "id": "z4ZOtU6KVfLS"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Grab a random Text Sequence"
      ],
      "metadata": {
        "id": "dNRrv-73VfLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_sequences[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:28.126442Z",
          "iopub.execute_input": "2021-11-20T16:37:28.126713Z",
          "iopub.status.idle": "2021-11-20T16:37:28.131913Z",
          "shell.execute_reply.started": "2021-11-20T16:37:28.126681Z",
          "shell.execute_reply": "2021-11-20T16:37:28.131128Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDyWvbaCVfLS",
        "outputId": "9ef1acd8-ae4e-41c2-8e39-7f43adddb0c8"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['etymology', 'supplied', 'by', 'a', 'late', 'consumptive', 'usher', 'to', 'a', 'grammar', 'school', 'the', 'pale', 'usher', 'threadbare', 'in', 'coat', 'heart', 'body', 'and', 'brain', 'i', 'see', 'him', 'now', 'he']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_pick = random.randint(0,len(text_sequences))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:30.041448Z",
          "iopub.execute_input": "2021-11-20T16:37:30.042068Z",
          "iopub.status.idle": "2021-11-20T16:37:30.046434Z",
          "shell.execute_reply.started": "2021-11-20T16:37:30.042021Z",
          "shell.execute_reply": "2021-11-20T16:37:30.045312Z"
        },
        "trusted": true,
        "id": "oLRnbufyVfLS"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed_text = text_sequences[random_pick]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:31.844613Z",
          "iopub.execute_input": "2021-11-20T16:37:31.845195Z",
          "iopub.status.idle": "2021-11-20T16:37:31.848788Z",
          "shell.execute_reply.started": "2021-11-20T16:37:31.845154Z",
          "shell.execute_reply": "2021-11-20T16:37:31.847994Z"
        },
        "trusted": true,
        "id": "Y-reSpzhVfLT"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_seed_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:39.477314Z",
          "iopub.execute_input": "2021-11-20T16:37:39.477576Z",
          "iopub.status.idle": "2021-11-20T16:37:39.484502Z",
          "shell.execute_reply.started": "2021-11-20T16:37:39.477544Z",
          "shell.execute_reply": "2021-11-20T16:37:39.482983Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJzhpujlVfLT",
        "outputId": "507b4e15-e5a2-499f-de15-00402d95e6c7"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gain', 'the', 'power', 'of', 'enlightening', 'his', 'untutored', 'countrymen', 'for', 'at', 'bottom', 'so', 'he', 'told', 'me', 'he', 'was', 'actuated', 'by', 'a', 'profound', 'desire', 'to', 'learn', 'among', 'the']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = ' '.join(random_seed_text)\n",
        "seed_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:42.706223Z",
          "iopub.execute_input": "2021-11-20T16:37:42.706493Z",
          "iopub.status.idle": "2021-11-20T16:37:42.711981Z",
          "shell.execute_reply.started": "2021-11-20T16:37:42.706461Z",
          "shell.execute_reply": "2021-11-20T16:37:42.710855Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BVOoYUPLVfLT",
        "outputId": "43452001-be6f-4a6a-e7a7-3ebebea74b1a"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gain the power of enlightening his untutored countrymen for at bottom so he told me he was actuated by a profound desire to learn among the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('epochBIG.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:48.916279Z",
          "iopub.execute_input": "2021-11-20T16:37:48.916602Z",
          "iopub.status.idle": "2021-11-20T16:37:49.440778Z",
          "shell.execute_reply.started": "2021-11-20T16:37:48.916564Z",
          "shell.execute_reply": "2021-11-20T16:37:49.440058Z"
        },
        "trusted": true,
        "id": "sVdQs2-kVfLT"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = load(open('epochBIG', 'rb'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:37:51.633034Z",
          "iopub.execute_input": "2021-11-20T16:37:51.633597Z",
          "iopub.status.idle": "2021-11-20T16:37:51.649065Z",
          "shell.execute_reply.started": "2021-11-20T16:37:51.633554Z",
          "shell.execute_reply": "2021-11-20T16:37:51.648321Z"
        },
        "trusted": true,
        "id": "9WWcl5Y2VfLT"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:38:11.751635Z",
          "iopub.execute_input": "2021-11-20T16:38:11.752481Z",
          "iopub.status.idle": "2021-11-20T16:38:12.459876Z",
          "shell.execute_reply.started": "2021-11-20T16:38:11.752441Z",
          "shell.execute_reply": "2021-11-20T16:38:12.459188Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "l1HxnDDJVfLT",
        "outputId": "e6f0d979-d90a-480e-b5ac-10a8c74c0be5"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 904ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'christians the arts'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=' It is a way I have of driving off the spleen and regulating the circulation.  Whenever I find'\n",
        "print(text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:39:20.486263Z",
          "iopub.execute_input": "2021-11-20T16:39:20.486518Z",
          "iopub.status.idle": "2021-11-20T16:39:20.490645Z",
          "shell.execute_reply.started": "2021-11-20T16:39:20.486488Z",
          "shell.execute_reply": "2021-11-20T16:39:20.489963Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5YL7zXSVfLT",
        "outputId": "65fb8506-45d5-498c-ced9-8714397470a5"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " It is a way I have of driving off the spleen and regulating the circulation.  Whenever I find\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=text,num_gen_words=3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:39:30.256536Z",
          "iopub.execute_input": "2021-11-20T16:39:30.256826Z",
          "iopub.status.idle": "2021-11-20T16:39:30.374387Z",
          "shell.execute_reply.started": "2021-11-20T16:39:30.256774Z",
          "shell.execute_reply": "2021-11-20T16:39:30.373659Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "mdnrnwEiVfLT",
        "outputId": "65550df0-2f3b-4992-e075-d49f08544005"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'myself involuntarily single'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(read_file('whale2.txt')[250000:251000])"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2021-11-20T16:41:47.972215Z",
          "iopub.execute_input": "2021-11-20T16:41:47.973069Z",
          "iopub.status.idle": "2021-11-20T16:41:47.982643Z",
          "shell.execute_reply.started": "2021-11-20T16:41:47.973029Z",
          "shell.execute_reply": "2021-11-20T16:41:47.981155Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5vOfF3vVfLT",
        "outputId": "3d4e1e54-a94e-4c5a-dcf0-cf4899a72b5b"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text='Three better,more likely sea-officers and men, each in his own different way,could not readily be found, and they were every'\n",
        "print(test_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:44:48.821574Z",
          "iopub.execute_input": "2021-11-20T16:44:48.821861Z",
          "iopub.status.idle": "2021-11-20T16:44:48.826424Z",
          "shell.execute_reply.started": "2021-11-20T16:44:48.821827Z",
          "shell.execute_reply": "2021-11-20T16:44:48.825507Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LJwfNGKVfLT",
        "outputId": "f6473c5d-3126-424c-ecf9-459f65787528"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Three better,more likely sea-officers and men, each in his own different way,could not readily be found, and they were every\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=test_text,num_gen_words=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-20T16:45:51.364504Z",
          "iopub.execute_input": "2021-11-20T16:45:51.364775Z",
          "iopub.status.idle": "2021-11-20T16:45:51.412311Z",
          "shell.execute_reply.started": "2021-11-20T16:45:51.364739Z",
          "shell.execute_reply": "2021-11-20T16:45:51.411630Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_-o-per7VfLT",
        "outputId": "d533fc46-ca62-46ce-a639-457a877d1fda"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'first'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"landsman has had fresh fruit to his daily hand and broken the world 's fresh bread to my mouldy crusts away whole oceans away from that\""
      ],
      "metadata": {
        "trusted": true,
        "id": "-wzWEeDiVfLT"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=5)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "2dR48cIzVfLU",
        "outputId": "de8511a7-7cbd-4428-f79e-f5f993927189"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a way i mean also'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YsxB1oUUaxPY"
      },
      "execution_count": 220,
      "outputs": []
    }
  ]
}